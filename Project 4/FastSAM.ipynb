{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(\"HOME:\", HOME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKHQNhU4H-7V",
        "outputId": "a97166cf-845a-4190-f679-c809c13d072f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOME: /content/yolov5/FastSAM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}\n",
        "\n",
        "# install FastSAM\n",
        "!git clone https://github.com/CASIA-IVA-Lab/FastSAM.git\n",
        "!pip -q install -r FastSAM/requirements.txt\n",
        "# install CLIP\n",
        "!pip -q install git+https://github.com/openai/CLIP.git\n",
        "# install SAM\n",
        "!pip -q install git+https://github.com/facebookresearch/segment-anything.git\n",
        "# install other dependencies\n",
        "!pip -q install roboflow supervision jupyter_bbox_widget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o2Nee-IIDna",
        "outputId": "7fe7882f-4e47-45b3-962b-df4e83358625"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5/FastSAM\n",
            "Cloning into 'FastSAM'...\n",
            "remote: Enumerating objects: 1329, done.\u001b[K\n",
            "remote: Counting objects: 100% (494/494), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 1329 (delta 377), reused 399 (delta 338), pack-reused 835\u001b[K\n",
            "Receiving objects: 100% (1329/1329), 72.57 MiB | 43.74 MiB/s, done.\n",
            "Resolving deltas: 100% (530/530), done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {HOME}/weights\n",
        "!wget -P {HOME}/weights -q https://huggingface.co/spaces/An-619/FastSAM/resolve/main/weights/FastSAM.pt\n",
        "!wget -P {HOME}/weights -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n",
        "!ls -lh {HOME}/weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YP0JLN5kIJDa",
        "outputId": "8b53fa0f-1311-4171-c847-f2b764251e8e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 2.6G\n",
            "-rw-r--r-- 1 root root 139M Jun 20  2023 FastSAM.pt\n",
            "-rw-r--r-- 1 root root 2.4G Apr  4  2023 sam_vit_h_4b8939.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FAST_SAM_CHECKPOINT_PATH = f\"{HOME}/weights/FastSAM.pt\"\n",
        "SAM_SAM_CHECKPOINT_PATH = f\"{HOME}/weights/sam_vit_h_4b8939.pth\""
      ],
      "metadata": {
        "id": "Q0x4GZ6gIJ-R"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#clone YOLOv5 and\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naopjKCo9BcY",
        "outputId": "a5de509d-18d1-4266-c711-2da74ecb5f48"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 16772, done.\u001b[K\n",
            "remote: Counting objects: 100% (93/93), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 16772 (delta 39), reused 45 (delta 20), pack-reused 16679\u001b[K\n",
            "Receiving objects: 100% (16772/16772), 15.39 MiB | 27.65 MiB/s, done.\n",
            "Resolving deltas: 100% (11518/11518), done.\n",
            "/content/yolov5\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.2/800.2 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hSetup complete. Using torch 2.3.0+cu121 (Tesla T4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ],
      "metadata": {
        "id": "1p3mpnY34ca5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"qmXdlsKqVuURfIBX1JvQ\")\n",
        "project = rf.workspace(\"proj-sfl83\").project(\"grasp-6\")\n",
        "version = project.version(7)\n",
        "dataset = version.download(\"yolov5\")"
      ],
      "metadata": {
        "id": "VWlCoga64dM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1df7716-a1f3-4366-f4d9-652fd8eebaa0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in /content/datasets/grasp-6-7 to yolov5pytorch:: 100%|██████████| 142498/142498 [00:04<00:00, 30160.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Dataset Version Zip to /content/datasets/grasp-6-7 in yolov5pytorch:: 100%|██████████| 6184/6184 [00:01<00:00, 5278.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --img 416 --batch 16 --epochs 30 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache"
      ],
      "metadata": {
        "id": "KZjjs-9o4ner",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3826276c-e953-4a25-9428-3c263e25af85"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-07-12 17:05:52.534207: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-12 17:05:52.534258: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-12 17:05:52.535908: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/content/datasets/grasp-6-7/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-339-g150a1a31 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 27.7MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 194MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=19\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     64728  models.yolo.Detect                      [19, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7070872 parameters, 7070872 gradients, 16.1 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/grasp-6-7/train/labels... 2517 images, 3 backgrounds, 0 corrupt: 100% 2517/2517 [00:02<00:00, 1203.93it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/grasp-6-7/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.2GB ram): 100% 2517/2517 [00:15<00:00, 161.24it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/grasp-6-7/valid/labels... 212 images, 0 backgrounds, 0 corrupt: 100% 212/212 [00:00<00:00, 436.11it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/grasp-6-7/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 212/212 [00:02<00:00, 91.08it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.04 anchors/target, 0.997 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 416 train, 416 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      1.57G    0.08248     0.0398    0.07633         23        416: 100% 158/158 [00:40<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:03<00:00,  1.83it/s]\n",
            "                   all        212        620      0.112      0.367      0.128     0.0673\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      1.73G     0.0541    0.03121    0.06721         23        416: 100% 158/158 [00:34<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.74it/s]\n",
            "                   all        212        620      0.673      0.187      0.206      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      1.73G    0.05136    0.02842    0.05733         13        416: 100% 158/158 [00:34<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.68it/s]\n",
            "                   all        212        620      0.507      0.318      0.379      0.211\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      1.74G    0.04564    0.02645     0.0475         31        416: 100% 158/158 [00:34<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.89it/s]\n",
            "                   all        212        620      0.544      0.461      0.494      0.318\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      1.74G    0.04256    0.02661    0.03826         36        416: 100% 158/158 [00:33<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.53it/s]\n",
            "                   all        212        620      0.567       0.57      0.612      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      1.74G    0.03936    0.02544    0.03175         28        416: 100% 158/158 [00:32<00:00,  4.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.80it/s]\n",
            "                   all        212        620      0.659      0.687      0.732      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      1.74G    0.03751    0.02446    0.02746         23        416: 100% 158/158 [00:31<00:00,  5.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.66it/s]\n",
            "                   all        212        620      0.796      0.724      0.798      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      1.74G    0.03623    0.02448    0.02274         30        416: 100% 158/158 [00:32<00:00,  4.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.67it/s]\n",
            "                   all        212        620      0.859      0.735      0.811      0.585\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      1.74G    0.03493    0.02443    0.02011         53        416: 100% 158/158 [00:32<00:00,  4.87it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.81it/s]\n",
            "                   all        212        620      0.908      0.748      0.861      0.609\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      1.74G     0.0339    0.02396    0.01815         32        416: 100% 158/158 [00:32<00:00,  4.82it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.87it/s]\n",
            "                   all        212        620      0.876      0.782      0.872      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      1.74G    0.03297    0.02324    0.01739         32        416: 100% 158/158 [00:33<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.69it/s]\n",
            "                   all        212        620      0.789      0.835      0.868      0.628\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      1.74G    0.03191    0.02343    0.01605         22        416: 100% 158/158 [00:34<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.79it/s]\n",
            "                   all        212        620      0.864      0.811      0.886      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      1.74G    0.03151    0.02277    0.01464         44        416: 100% 158/158 [00:33<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.92it/s]\n",
            "                   all        212        620      0.821      0.828      0.885      0.699\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      1.74G    0.03058    0.02275    0.01392         14        416: 100% 158/158 [00:34<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.88it/s]\n",
            "                   all        212        620      0.882      0.757       0.87      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      1.74G     0.0303    0.02193    0.01315         24        416: 100% 158/158 [00:32<00:00,  4.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.61it/s]\n",
            "                   all        212        620      0.874       0.79       0.88       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      1.74G     0.0287    0.02183    0.01215         32        416: 100% 158/158 [00:34<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.92it/s]\n",
            "                   all        212        620      0.845       0.82      0.868       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      1.74G    0.02861    0.02152    0.01178         44        416: 100% 158/158 [00:33<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.95it/s]\n",
            "                   all        212        620      0.796       0.84      0.858      0.677\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      1.74G    0.02794     0.0214    0.01132         34        416: 100% 158/158 [00:32<00:00,  4.83it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.61it/s]\n",
            "                   all        212        620      0.824      0.873      0.913      0.727\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      1.74G    0.02751    0.02115    0.01104         21        416: 100% 158/158 [00:32<00:00,  4.93it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.70it/s]\n",
            "                   all        212        620      0.885      0.823      0.897      0.734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      1.74G    0.02731    0.02153    0.01024         26        416: 100% 158/158 [00:31<00:00,  5.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.77it/s]\n",
            "                   all        212        620      0.885      0.825      0.911      0.743\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      1.74G    0.02634     0.0212   0.009359         31        416: 100% 158/158 [00:33<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.75it/s]\n",
            "                   all        212        620      0.879      0.809      0.912      0.738\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      1.74G    0.02612    0.02066   0.009318         46        416: 100% 158/158 [00:34<00:00,  4.57it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.97it/s]\n",
            "                   all        212        620      0.878      0.838      0.907       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      1.74G    0.02536    0.02021   0.008653         24        416: 100% 158/158 [00:33<00:00,  4.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.98it/s]\n",
            "                   all        212        620      0.888      0.815      0.916      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      1.74G    0.02461    0.02038   0.008751         21        416: 100% 158/158 [00:33<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.92it/s]\n",
            "                   all        212        620      0.859      0.807      0.904      0.742\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      1.74G    0.02462    0.02017   0.008199         39        416: 100% 158/158 [00:33<00:00,  4.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  3.34it/s]\n",
            "                   all        212        620      0.864      0.834      0.918      0.758\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      1.74G    0.02387    0.01971   0.008179         30        416: 100% 158/158 [00:32<00:00,  4.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.73it/s]\n",
            "                   all        212        620      0.878      0.849      0.894      0.744\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      1.74G    0.02345    0.01964   0.007651         35        416: 100% 158/158 [00:29<00:00,  5.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:02<00:00,  2.95it/s]\n",
            "                   all        212        620      0.847      0.849       0.91      0.752\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      1.74G    0.02281     0.0192   0.007059         22        416: 100% 158/158 [00:30<00:00,  5.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  4.01it/s]\n",
            "                   all        212        620      0.884      0.811      0.923      0.769\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      1.74G    0.02284    0.01926   0.007099         25        416: 100% 158/158 [00:32<00:00,  4.85it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.99it/s]\n",
            "                   all        212        620      0.863       0.84      0.919      0.772\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      1.74G    0.02192    0.01856   0.006878         56        416: 100% 158/158 [00:33<00:00,  4.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:01<00:00,  3.99it/s]\n",
            "                   all        212        620      0.875       0.84      0.926      0.782\n",
            "\n",
            "30 epochs completed in 0.301 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7061368 parameters, 0 gradients, 15.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 7/7 [00:03<00:00,  1.80it/s]\n",
            "                   all        212        620      0.875       0.84      0.926      0.783\n",
            "                banana        212         72      0.993      0.958      0.979      0.905\n",
            "               biscuit        212          8      0.631          1      0.995      0.803\n",
            "                  cake        212          8      0.863          1      0.995      0.874\n",
            "           cup-laying-        212          8      0.546      0.875      0.902      0.818\n",
            "         cup-standing-        212          8      0.815          1      0.995      0.918\n",
            "                  fork        212         12          1      0.768      0.995      0.739\n",
            "         juice-laying-        212         13      0.932          1      0.995      0.891\n",
            "       juice-standing-        212         31      0.965          1      0.995      0.888\n",
            "                 knife        212          5          1      0.666      0.995      0.812\n",
            "                  logo        212         37      0.786      0.838      0.766       0.63\n",
            "               nescafe        212         40      0.914      0.533      0.643       0.46\n",
            "       nescafe-square-        212         24      0.281      0.833      0.752       0.67\n",
            "                  pack        212         34          1      0.959      0.995      0.865\n",
            "          rani-laying-        212         18      0.982          1      0.995      0.896\n",
            "        rani-standing-        212         13      0.984          1      0.995      0.882\n",
            "                 spoon        212         14      0.949          1      0.995      0.828\n",
            "                 straw        212          5          1       0.53      0.928      0.609\n",
            "             tangerine        212         79      0.987      0.975      0.985      0.846\n",
            "                   tea        212        191          1     0.0266      0.699      0.539\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1dQHYhE6f3N",
        "outputId": "30e14556-282e-4ee8-c74d-2241e785fc42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/test_images/\n",
        "!cp /content/drive/MyDrive/test_images/* /content/test_images/"
      ],
      "metadata": {
        "id": "4dBysZY96g7b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHpkQB65LeiV",
        "outputId": "e039f3bf-2cee-4e21-c92a-90879ccd291e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.2.55)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.5.82)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd {HOME}/FastSAM\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import roboflow\n",
        "import base64\n",
        "\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "\n",
        "from roboflow import Roboflow\n",
        "from fastsam import FastSAM\n",
        "# Load your YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/exp/weights/best.pt')\n",
        "\n",
        "# Load your test images\n",
        "img_paths = ['/content/test_images/IMG_1246.JPG', '/content/test_images/IMG_1246.JPG']\n",
        "images = [cv2.imread(img_path) for img_path in img_paths]\n",
        "\n",
        "# Get bounding boxes from YOLOv5\n",
        "results = model(images)\n",
        "bboxes = results.xyxy  # bounding boxes\n",
        "\n",
        "# Step 3: Run FastSAM with Bounding Boxes\n",
        "\n",
        "\n",
        "\n",
        "# Initialize FastSAM\n",
        "fast_sam = fastsam()\n",
        "\n",
        "# Function to convert YOLOv5 bounding boxes to FastSAM format\n",
        "def yolo_to_fastsam_bbox(yolo_bbox):\n",
        "    # Convert YOLOv5 bbox (x1, y1, x2, y2) to FastSAM bbox (x, y, width, height)\n",
        "    x1, y1, x2, y2 = yolo_bbox\n",
        "    return [x1, y1, x2 - x1, y2 - y1]\n",
        "\n",
        "# Segment each image using FastSAM\n",
        "segmented_images = []\n",
        "for img, bbox in zip(images, bboxes):\n",
        "    fast_sam_bbox = yolo_to_fastsam_bbox(bbox)\n",
        "    mask = fast_sam.segment(img, bbox=fast_sam_bbox)\n",
        "    segmented_images.append(mask)\n",
        "\n",
        "# Step 4: Visualize the Segmented Images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images_with_masks(images, masks):\n",
        "    for i, (img, mask) in enumerate(zip(images, masks)):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(\"Original Image\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title(\"Segmented Mask\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "plot_images_with_masks(images, segmented_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "fIqXT5PKEhxf",
        "outputId": "498a0577-0a62-4374-f322-5f2a4a8b8d35",
        "collapsed": true
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5/FastSAM/FastSAM\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics.yolo'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-fb3abea8a3ad>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mroboflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRoboflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfastsam\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# Load your YOLOv5 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ultralytics/yolov5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'custom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/yolov5/runs/train/exp/weights/best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/yolov5/FastSAM/FastSAM/fastsam/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAMPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mprompt\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastSAMPrompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/yolov5/FastSAM/FastSAM/fastsam/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \"\"\"\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExporter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics.yolo'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}